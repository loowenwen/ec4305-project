{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48928be5",
   "metadata": {},
   "source": [
    "# HDB Resale Price Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43465c",
   "metadata": {},
   "source": [
    "**Models implemented:**\n",
    "1. Linear Regression (OLS)\n",
    "2. Non-linear Regression (polynomial terms for selected variables)\n",
    "3. IV Regression (2SLS, exploratory)\n",
    "4. LASSO\n",
    "5. Ridge\n",
    "6. Elastic Net\n",
    "7. Stepwise Selection (forward, on a subset of features)\n",
    "\n",
    "**Common settings:**\n",
    "- 80/20 train-test split\n",
    "- 5-fold Cross-Validation (CV) for hypertuning\n",
    "- RMSE used as main metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e2db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c1e541",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b88751",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/HDB_data_2021_sample.xlsx\"\n",
    "\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "# drop rows with missing resale_price\n",
    "df = df.dropna(subset=[\"resale_price\"])\n",
    "\n",
    "# define target: use log(price) for nicer regression properties\n",
    "df[\"log_resale_price\"] = np.log(df[\"resale_price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda136a",
   "metadata": {},
   "source": [
    "### Feature Selection for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10deaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for \"full\" models (OLS, LASSO, Ridge, ENet)\n",
    "# we'll use all columns except the target and year (year is constant 2021)\n",
    "drop_cols_full = [\"resale_price\", \"log_resale_price\", \"year\"]\n",
    "X_full = df.drop(columns=drop_cols_full)\n",
    "y = df[\"log_resale_price\"].values\n",
    "\n",
    "feature_names_full = X_full.columns.tolist()\n",
    "\n",
    "# for non-linear regression & stepwise & IV,\n",
    "# we work with a smaller, interpretable subset to keep things manageable.\n",
    "nonlinear_features = [\n",
    "    \"floor_area_sqm\",\n",
    "    \"Remaining_lease\",\n",
    "    \"max_floor_lvl\",\n",
    "    \"mature\",\n",
    "    \"Dist_CBD\",\n",
    "    \"Dist_nearest_station\",\n",
    "    \"Dist_nearest_hospital\",\n",
    "]\n",
    "\n",
    "# keep only those columns that actually exist in the dataframe\n",
    "nonlinear_features = [f for f in nonlinear_features if f in df.columns]\n",
    "\n",
    "X_small = df[nonlinear_features].copy()\n",
    "feature_names_small = X_small.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7c419",
   "metadata": {},
   "source": [
    "## Train-Test Split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5903bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_train, X_full_test, y_train, y_test = train_test_split(\n",
    "    X_full, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_small_train, X_small_test, y_small_train, y_small_test = train_test_split(\n",
    "    X_small, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d8f0a",
   "metadata": {},
   "source": [
    "## Utility: Compute RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2457de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c470d98",
   "metadata": {},
   "source": [
    "## Linear Regression (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6107afbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline OLS - Train RMSE: 0.0732\n",
      "Baseline OLS - Test  RMSE: 0.0772\n"
     ]
    }
   ],
   "source": [
    "# baseline: simple OLS on full feature set\n",
    "ols_baseline = LinearRegression()\n",
    "ols_baseline.fit(X_full_train, y_train)\n",
    "\n",
    "y_pred_train_ols = ols_baseline.predict(X_full_train)\n",
    "y_pred_test_ols = ols_baseline.predict(X_full_test)\n",
    "\n",
    "print(f\"Baseline OLS - Train RMSE: {rmse(y_train, y_pred_train_ols):.4f}\")\n",
    "print(f\"Baseline OLS - Test  RMSE: {rmse(y_test, y_pred_test_ols):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703664d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS 5-fold CV RMSE (train): 0.0770 (std: 0.0011)\n"
     ]
    }
   ],
   "source": [
    "# \"hypertuned\" OLS:\n",
    "# there's no real hyperparameter to tune for plain OLS,\n",
    "# but we can do a 5-fold CV on the training data to estimate expected RMSE\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_rmse_scores = []\n",
    "for train_idx, val_idx in kf.split(X_full_train):\n",
    "    X_tr, X_val = X_full_train.iloc[train_idx], X_full_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    cv_rmse_scores.append(rmse(y_val, y_val_pred))\n",
    "\n",
    "print(f\"OLS 5-fold CV RMSE (train): {np.mean(cv_rmse_scores):.4f} \"\n",
    "      f\"(std: {np.std(cv_rmse_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc3b311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 OLS coefficients by absolute magnitude:\n",
      "flat_model_terrace                0.626531\n",
      "postal_2digits_50                 0.267955\n",
      "flat_model_2.room                 0.260992\n",
      "flat_model_improved.maisonette    0.237784\n",
      "town_BUKIT.TIMAH                  0.226117\n",
      "postal_2digits_51                 0.209441\n",
      "postal_2digits_18                 0.202498\n",
      "flat_type_2.ROOM                  0.183313\n",
      "postal_2digits_37                 0.173624\n",
      "flat_model_type.s2                0.170621\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# coefficient-based \"feature importance\" for OLS\n",
    "ols_coefs = pd.Series(ols_baseline.coef_, index=feature_names_full)\n",
    "print(\"\\nTop 10 OLS coefficients by absolute magnitude:\")\n",
    "print(ols_coefs.abs().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c78cac",
   "metadata": {},
   "source": [
    "## Non-Linear Regression (Polynomial Terms on Selected Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033f118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Poly (deg=2) - Train RMSE: 0.1068\n",
      "Baseline Poly (deg=2) - Test  RMSE: 0.1089\n"
     ]
    }
   ],
   "source": [
    "# baseline: degree=2 polynomial on selected features, Linear Regression\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly_train = poly.fit_transform(X_small_train)\n",
    "X_poly_test = poly.transform(X_small_test)\n",
    "\n",
    "poly_feature_names = poly.get_feature_names_out(feature_names_small)\n",
    "\n",
    "poly_ols_baseline = LinearRegression()\n",
    "poly_ols_baseline.fit(X_poly_train, y_small_train)\n",
    "\n",
    "y_pred_train_poly = poly_ols_baseline.predict(X_poly_train)\n",
    "y_pred_test_poly = poly_ols_baseline.predict(X_poly_test)\n",
    "\n",
    "print(f\"Baseline Poly (deg=2) - Train RMSE: {rmse(y_small_train, y_pred_train_poly):.4f}\")\n",
    "print(f\"Baseline Poly (deg=2) - Test  RMSE: {rmse(y_small_test, y_pred_test_poly):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75b2265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 Poly - 5-fold CV RMSE: 0.1205\n",
      "Degree 2 Poly - 5-fold CV RMSE: 0.1079\n",
      "Degree 3 Poly - 5-fold CV RMSE: 0.1022\n",
      "Best polynomial degree (by CV RMSE): 3\n"
     ]
    }
   ],
   "source": [
    "# hypertuned: try degrees 1, 2, 3 with 5-fold CV\n",
    "best_degree = None\n",
    "best_cv_rmse = np.inf\n",
    "\n",
    "for degree in [1, 2, 3]:\n",
    "    poly_tmp = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly_tmp = poly_tmp.fit_transform(X_small_train)\n",
    "\n",
    "    cv_rmse_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_poly_tmp):\n",
    "        X_tr, X_val = X_poly_tmp[train_idx], X_poly_tmp[val_idx]\n",
    "        y_tr, y_val = y_small_train[train_idx], y_small_train[val_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        cv_rmse_scores.append(rmse(y_val, y_val_pred))\n",
    "\n",
    "    mean_cv_rmse = np.mean(cv_rmse_scores)\n",
    "    print(f\"Degree {degree} Poly - 5-fold CV RMSE: {mean_cv_rmse:.4f}\")\n",
    "\n",
    "    if mean_cv_rmse < best_cv_rmse:\n",
    "        best_cv_rmse = mean_cv_rmse\n",
    "        best_degree = degree\n",
    "\n",
    "print(f\"Best polynomial degree (by CV RMSE): {best_degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9c446e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Poly (deg=3) - Test RMSE: 0.1019\n"
     ]
    }
   ],
   "source": [
    "# fit final tuned model with best degree\n",
    "poly_best = PolynomialFeatures(degree=best_degree, include_bias=False)\n",
    "X_poly_train_best = poly_best.fit_transform(X_small_train)\n",
    "X_poly_test_best = poly_best.transform(X_small_test)\n",
    "\n",
    "poly_ols_tuned = LinearRegression()\n",
    "poly_ols_tuned.fit(X_poly_train_best, y_small_train)\n",
    "\n",
    "y_pred_test_poly_tuned = poly_ols_tuned.predict(X_poly_test_best)\n",
    "print(f\"Tuned Poly (deg={best_degree}) - Test RMSE: {rmse(y_small_test, y_pred_test_poly_tuned):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f4e2d",
   "metadata": {},
   "source": [
    "## IV Regression (2SLS, Exploratory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd8081aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First-stage coefficients (endogenous on instruments + exog):\n",
      "max_floor_lvl           1.082473\n",
      "Dist_CBD                1.033363\n",
      "floor_area_sqm          0.001078\n",
      "Dist_nearest_station   -4.292930\n",
      "mature                 -6.489360\n",
      "dtype: float64\n",
      "\n",
      "Second-stage 2SLS (manual) results:\n",
      "2SLS In-sample RMSE: 0.1558\n",
      "\n",
      "2SLS coefficients:\n",
      "mature                  0.192252\n",
      "Remaining_lease_hat     0.016818\n",
      "floor_area_sqm          0.009868\n",
      "Dist_nearest_station   -0.020500\n",
      "Dist_CBD               -0.026934\n",
      "dtype: float64\n",
      "\n",
      "2SLS intercept: 11.0784\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "IMPORTANT:\n",
    "This is a SIMPLE 2SLS implementation WITHOUT statsmodels.\n",
    "\n",
    "You must define:\n",
    "- endog_var: the (suspected) endogenous regressor\n",
    "- instrument_vars: list of instruments\n",
    "- exog_vars: other exogenous controls\n",
    "\n",
    "Below is just an EXAMPLE SETUP - you should adjust to what makes sense\n",
    "economically for your project.\n",
    "\"\"\"\n",
    "\n",
    "# example variable choices – EDIT to match your actual IV story\n",
    "endog_var = \"Remaining_lease\"          # endogenous regressor candidate\n",
    "instrument_vars = [\"max_floor_lvl\"]    # instrument(s) – purely illustrative!\n",
    "base_exog_vars = [\"floor_area_sqm\", \"mature\", \"Dist_CBD\", \"Dist_nearest_station\"]\n",
    "\n",
    "# keep only variables that exist\n",
    "iv_all_vars = [endog_var] + instrument_vars + base_exog_vars + [\"log_resale_price\"]\n",
    "iv_all_vars = [v for v in iv_all_vars if v in df.columns]\n",
    "\n",
    "iv_data = df[iv_all_vars].dropna()\n",
    "\n",
    "if endog_var not in iv_data.columns or not all(z in iv_data.columns for z in instrument_vars):\n",
    "    print(\"IV example not run: check that endog and instrument columns exist in df.\")\n",
    "else:\n",
    "    # define y, endogenous regressor, instruments, and exog controls\n",
    "    y_iv = iv_data[\"log_resale_price\"].values\n",
    "    endog = iv_data[[endog_var]]                      # (n, 1)\n",
    "    Z = iv_data[instrument_vars]                      # instruments\n",
    "    exog = iv_data[[v for v in base_exog_vars if v in iv_data.columns]]\n",
    "\n",
    "    # 2a. first stage: endog ~ instruments + exog\n",
    "    X_first = pd.concat([Z, exog], axis=1)\n",
    "    first_stage_model = LinearRegression()\n",
    "    first_stage_model.fit(X_first, endog)\n",
    "\n",
    "    endog_hat = first_stage_model.predict(X_first)    # predicted Remaining_lease\n",
    "\n",
    "    print(\"\\nFirst-stage coefficients (endogenous on instruments + exog):\")\n",
    "    first_stage_coefs = pd.Series(\n",
    "        first_stage_model.coef_.ravel(),\n",
    "        index=X_first.columns\n",
    "    )\n",
    "    print(first_stage_coefs.sort_values(ascending=False))\n",
    "\n",
    "    # 2b. second stage: y ~ predicted_endog + exog\n",
    "    X_second = pd.concat(\n",
    "        [pd.Series(endog_hat.ravel(), name=f\"{endog_var}_hat\"), exog.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    second_stage_model = LinearRegression()\n",
    "    second_stage_model.fit(X_second, y_iv)\n",
    "\n",
    "    y_iv_pred = second_stage_model.predict(X_second)\n",
    "    iv_rmse = rmse(y_iv, y_iv_pred)\n",
    "\n",
    "    print(\"\\nSecond-stage 2SLS (manual) results:\")\n",
    "    print(f\"2SLS In-sample RMSE: {iv_rmse:.4f}\")\n",
    "\n",
    "    second_stage_coefs = pd.Series(\n",
    "        second_stage_model.coef_,\n",
    "        index=X_second.columns\n",
    "    )\n",
    "    print(\"\\n2SLS coefficients:\")\n",
    "    print(second_stage_coefs.sort_values(ascending=False))\n",
    "\n",
    "    print(f\"\\n2SLS intercept: {second_stage_model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e6dbf",
   "metadata": {},
   "source": [
    "## Penalised Regressions: LASSO, Ridge, Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a790569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise features for penalised models\n",
    "scaler = StandardScaler()\n",
    "X_full_train_scaled = scaler.fit_transform(X_full_train)\n",
    "X_full_test_scaled = scaler.transform(X_full_test)\n",
    "\n",
    "# helper: run baseline & tuned penalised model with GridSearchCV\n",
    "def run_penalised_model(model_name, base_model, param_grid):\n",
    "    \"\"\"\n",
    "    model_name: str (\"LASSO\", \"Ridge\", \"ElasticNet\")\n",
    "    base_model: sklearn estimator (Lasso, Ridge, ElasticNet)\n",
    "    param_grid: dict of hyperparameters for GridSearchCV\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "\n",
    "    # baseline: fit with default hyperparameters\n",
    "    base_model.fit(X_full_train_scaled, y_train)\n",
    "    y_pred_test_base = base_model.predict(X_full_test_scaled)\n",
    "    print(f\"{model_name} Baseline - Test RMSE: {rmse(y_test, y_pred_test_base):.4f}\")\n",
    "\n",
    "    # hypertuned with 5-fold CV\n",
    "    grid = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"neg_mean_squared_error\",  # we'll take sqrt later\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_full_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred_test_best = best_model.predict(X_full_test_scaled)\n",
    "    best_rmse = rmse(y_test, y_pred_test_best)\n",
    "\n",
    "    print(f\"{model_name} Tuned - Best Params: {grid.best_params_}\")\n",
    "    print(f\"{model_name} Tuned - Test RMSE:  {best_rmse:.4f}\")\n",
    "\n",
    "    # feature importance = absolute value of coefficients\n",
    "    coefs = pd.Series(best_model.coef_, index=feature_names_full)\n",
    "    print(f\"\\nTop 10 {model_name} coefficients by absolute magnitude:\")\n",
    "    print(coefs.abs().sort_values(ascending=False).head(10))\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34deef1",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeaee850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LASSO ---\n",
      "LASSO Baseline - Test RMSE: 0.3236\n",
      "LASSO Tuned - Best Params: {'alpha': 0.0005}\n",
      "LASSO Tuned - Test RMSE:  0.0774\n",
      "\n",
      "Top 10 LASSO coefficients by absolute magnitude:\n",
      "floor_area_sqm           0.178885\n",
      "Remaining_lease          0.154745\n",
      "Dist_CBD                 0.062814\n",
      "mature                   0.031116\n",
      "Dist_nearest_GHawker     0.030710\n",
      "storey_range_01.TO.03    0.027989\n",
      "flat_type_3.ROOM         0.027887\n",
      "max_floor_lvl            0.026193\n",
      "Dist_nearest_station     0.025844\n",
      "postal_2digits_44        0.024547\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "lasso_base = Lasso(max_iter=5000, random_state=42)\n",
    "lasso_param_grid = {\"alpha\": [0.0005, 0.001, 0.01, 0.1, 1.0]}\n",
    "best_lasso = run_penalised_model(\"LASSO\", lasso_base, lasso_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13684f1b",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0c59360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ridge ---\n",
      "Ridge Baseline - Test RMSE: 0.0773\n",
      "Ridge Tuned - Best Params: {'alpha': 1.0}\n",
      "Ridge Tuned - Test RMSE:  0.0773\n",
      "\n",
      "Top 10 Ridge coefficients by absolute magnitude:\n",
      "floor_area_sqm             0.162985\n",
      "Remaining_lease            0.153364\n",
      "Dist_CBD                   0.097727\n",
      "Dist_nearest_GAI_jc        0.073005\n",
      "Dist_nearest_university    0.071881\n",
      "Dist_nearest_jc            0.042982\n",
      "flat_type_3.ROOM           0.036832\n",
      "Dist_nearest_G_jc          0.034055\n",
      "Dist_nearest_station       0.034002\n",
      "flat_type_5.ROOM           0.030627\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ridge_base = Ridge(random_state=42)\n",
    "ridge_param_grid = {\"alpha\": [0.1, 1.0, 10.0, 100.0]}\n",
    "best_ridge = run_penalised_model(\"Ridge\", ridge_base, ridge_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27fb5b",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e68ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ElasticNet ---\n",
      "ElasticNet Baseline - Test RMSE: 0.3236\n",
      "ElasticNet Tuned - Best Params: {'alpha': 0.0005, 'l1_ratio': 0.2}\n",
      "ElasticNet Tuned - Test RMSE:  0.0771\n",
      "\n",
      "Top 10 ElasticNet coefficients by absolute magnitude:\n",
      "floor_area_sqm             0.165953\n",
      "Remaining_lease            0.153395\n",
      "Dist_CBD                   0.086982\n",
      "Dist_nearest_GAI_jc        0.040341\n",
      "mature                     0.037534\n",
      "Dist_nearest_university    0.034679\n",
      "flat_type_3.ROOM           0.033808\n",
      "Dist_nearest_station       0.031461\n",
      "flat_type_5.ROOM           0.030557\n",
      "storey_range_01.TO.03      0.028541\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "enet_base = ElasticNet(max_iter=5000, random_state=42)\n",
    "enet_param_grid = {\n",
    "    \"alpha\": [0.0005, 0.001, 0.01, 0.1, 1.0],\n",
    "    \"l1_ratio\": [0.2, 0.5, 0.8]\n",
    "}\n",
    "best_enet = run_penalised_model(\"ElasticNet\", enet_base, enet_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fbc4d",
   "metadata": {},
   "source": [
    "## Stepwise Selection (Forward) on a Subset of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ece3dd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: no features, CV RMSE = 0.3180\n",
      "  Try adding            floor_area_sqm -> CV RMSE = 0.2324\n",
      "  Try adding           Remaining_lease -> CV RMSE = 0.2915\n",
      "  Try adding             max_floor_lvl -> CV RMSE = 0.2796\n",
      "  Try adding                    mature -> CV RMSE = 0.3140\n",
      "  Try adding                  Dist_CBD -> CV RMSE = 0.3116\n",
      "  Try adding      Dist_nearest_station -> CV RMSE = 0.3160\n",
      "  Try adding     Dist_nearest_hospital -> CV RMSE = 0.3163\n",
      "--> Added floor_area_sqm, new best CV RMSE = 0.2324\n",
      "\n",
      "  Try adding           Remaining_lease -> CV RMSE = 0.2038\n",
      "  Try adding             max_floor_lvl -> CV RMSE = 0.1743\n",
      "  Try adding                    mature -> CV RMSE = 0.2198\n",
      "  Try adding                  Dist_CBD -> CV RMSE = 0.2035\n",
      "  Try adding      Dist_nearest_station -> CV RMSE = 0.2278\n",
      "  Try adding     Dist_nearest_hospital -> CV RMSE = 0.2236\n",
      "--> Added max_floor_lvl, new best CV RMSE = 0.1743\n",
      "\n",
      "  Try adding           Remaining_lease -> CV RMSE = 0.1677\n",
      "  Try adding                    mature -> CV RMSE = 0.1630\n",
      "  Try adding                  Dist_CBD -> CV RMSE = 0.1611\n",
      "  Try adding      Dist_nearest_station -> CV RMSE = 0.1725\n",
      "  Try adding     Dist_nearest_hospital -> CV RMSE = 0.1682\n",
      "--> Added Dist_CBD, new best CV RMSE = 0.1611\n",
      "\n",
      "  Try adding           Remaining_lease -> CV RMSE = 0.1300\n",
      "  Try adding                    mature -> CV RMSE = 0.1599\n",
      "  Try adding      Dist_nearest_station -> CV RMSE = 0.1586\n",
      "  Try adding     Dist_nearest_hospital -> CV RMSE = 0.1604\n",
      "--> Added Remaining_lease, new best CV RMSE = 0.1300\n",
      "\n",
      "  Try adding                    mature -> CV RMSE = 0.1223\n",
      "  Try adding      Dist_nearest_station -> CV RMSE = 0.1295\n",
      "  Try adding     Dist_nearest_hospital -> CV RMSE = 0.1300\n",
      "--> Added mature, new best CV RMSE = 0.1223\n",
      "\n",
      "  Try adding      Dist_nearest_station -> CV RMSE = 0.1206\n",
      "  Try adding     Dist_nearest_hospital -> CV RMSE = 0.1221\n",
      "--> Added Dist_nearest_station, new best CV RMSE = 0.1206\n",
      "\n",
      "  Try adding     Dist_nearest_hospital -> CV RMSE = 0.1205\n",
      "--> Added Dist_nearest_hospital, new best CV RMSE = 0.1205\n",
      "\n",
      "\n",
      "Selected features by forward stepwise (CV RMSE):\n",
      "['floor_area_sqm', 'max_floor_lvl', 'Dist_CBD', 'Remaining_lease', 'mature', 'Dist_nearest_station', 'Dist_nearest_hospital']\n",
      "Final CV RMSE (train): 0.1205\n",
      "\n",
      "Stepwise (CV-based) - Train RMSE: 0.1202\n",
      "Stepwise (CV-based) - Test  RMSE: 0.1193\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We:\n",
    "- start with no predictors,\n",
    "- at each step, try adding each remaining candidate variable,\n",
    "- for each tentative model, evaluate 5-fold CV RMSE,\n",
    "- add the variable that gives the biggest RMSE improvement,\n",
    "- stop when no variable improves RMSE.\n",
    "\n",
    "We use:\n",
    "- X_small_train, y_small_train  (subset of interpretable features)\n",
    "- X_small_test,  y_small_test   (to evaluate the final selected model)\n",
    "\"\"\"\n",
    "\n",
    "# use the same small feature set as before\n",
    "candidate_features = list(X_small_train.columns)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def cv_rmse_for_features(X, y, features, kf):\n",
    "    \"\"\"\n",
    "    compute K-fold CV RMSE for LinearRegression using\n",
    "    only the given list of features.\n",
    "    \"\"\"\n",
    "    if len(features) == 0:\n",
    "        # No features: predict mean\n",
    "        y_mean = np.mean(y)\n",
    "        return np.sqrt(np.mean((y - y_mean) ** 2))\n",
    "\n",
    "    X_sub = X[features].values\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_sub):\n",
    "        X_tr, X_val = X_sub[train_idx], X_sub[val_idx]\n",
    "        y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        rmse_scores.append(np.sqrt(np.mean((y_val - y_val_pred) ** 2)))\n",
    "\n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "\n",
    "def forward_stepwise_cv(X, y, candidate_features, kf, tol=1e-4, verbose=True):\n",
    "    \"\"\"\n",
    "    forward stepwise selection based on K-fold CV RMSE.\n",
    "\n",
    "    tol: minimum RMSE improvement required to keep adding variables.\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    remaining = list(candidate_features)\n",
    "    current_best_rmse = cv_rmse_for_features(X, y, selected, kf)\n",
    "    if verbose:\n",
    "        print(f\"Start: no features, CV RMSE = {current_best_rmse:.4f}\")\n",
    "\n",
    "    while len(remaining) > 0:\n",
    "        best_feature = None\n",
    "        best_rmse = current_best_rmse\n",
    "\n",
    "        # try adding each remaining variable and compute CV RMSE\n",
    "        for feat in remaining:\n",
    "            trial_features = selected + [feat]\n",
    "            trial_rmse = cv_rmse_for_features(X, y, trial_features, kf)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"  Try adding {feat:>25s} -> CV RMSE = {trial_rmse:.4f}\")\n",
    "\n",
    "            if trial_rmse + tol < best_rmse:\n",
    "                best_rmse = trial_rmse\n",
    "                best_feature = feat\n",
    "\n",
    "        # if we found a feature that improves RMSE, add it\n",
    "        if best_feature is not None:\n",
    "            selected.append(best_feature)\n",
    "            remaining.remove(best_feature)\n",
    "            current_best_rmse = best_rmse\n",
    "            if verbose:\n",
    "                print(f\"--> Added {best_feature}, new best CV RMSE = {current_best_rmse:.4f}\\n\")\n",
    "        else:\n",
    "            # no further improvement\n",
    "            if verbose:\n",
    "                print(\"No further improvement in CV RMSE. Stopping forward selection.\")\n",
    "            break\n",
    "\n",
    "    return selected, current_best_rmse\n",
    "\n",
    "# run forward stepwise on the training set\n",
    "selected_features, final_cv_rmse = forward_stepwise_cv(\n",
    "    X_small_train,\n",
    "    y_small_train,\n",
    "    candidate_features,\n",
    "    kf,\n",
    "    tol=1e-4,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nSelected features by forward stepwise (CV RMSE):\")\n",
    "print(selected_features)\n",
    "print(f\"Final CV RMSE (train): {final_cv_rmse:.4f}\")\n",
    "\n",
    "# fit final model on train, evaluate on test\n",
    "step_model = LinearRegression()\n",
    "step_model.fit(X_small_train[selected_features], y_small_train)\n",
    "\n",
    "y_step_train_pred = step_model.predict(X_small_train[selected_features])\n",
    "y_step_test_pred  = step_model.predict(X_small_test[selected_features])\n",
    "\n",
    "print(f\"\\nStepwise (CV-based) - Train RMSE: {rmse(y_small_train, y_step_train_pred):.4f}\")\n",
    "print(f\"Stepwise (CV-based) - Test  RMSE: {rmse(y_small_test,  y_step_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5387051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stepwise model coefficients:\n",
      "mature                   0.150569\n",
      "floor_area_sqm           0.009856\n",
      "Remaining_lease          0.009302\n",
      "max_floor_lvl            0.008149\n",
      "Dist_nearest_hospital   -0.006646\n",
      "Dist_CBD                -0.017627\n",
      "Dist_nearest_station    -0.055020\n",
      "dtype: float64\n",
      "\n",
      "Stepwise intercept: 11.4549\n"
     ]
    }
   ],
   "source": [
    "# coefficients for interpretation\n",
    "step_coefs = pd.Series(step_model.coef_, index=selected_features)\n",
    "print(\"\\nStepwise model coefficients:\")\n",
    "print(step_coefs.sort_values(ascending=False))\n",
    "print(f\"\\nStepwise intercept: {step_model.intercept_:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlackjackAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
